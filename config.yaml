llm:
  provider: "ollama"  # ollama | openrouter

  ollama:
    base_url: "http://localhost:11434"
    model: "gemma2:2b"  # Available: gemma2:2b, mistral:latest, llama2:latest, deepseek-r1:8b
    temperature: 0.7

  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    api_key_env: "OPENROUTER_API_KEY"
    model: "anthropic/claude-3.5-sonnet"
    temperature: 0.7

wikipedia:
  language: "en"
  max_articles: 3
  max_chars_per_article: 3000

agent:
  stream_response: true
  enforce_citations: true
