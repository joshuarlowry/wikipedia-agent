# Wikipedia Research Agent

A Wikipedia research agent powered by the **[Strands Agents framework](https://strandsagents.com/)** with an interactive Terminal UI that searches for relevant articles, synthesizes information using LLMs, and provides responses with proper MLA citations.

> **Note**: This project has been migrated to use the Strands Agents SDK for improved orchestration, multi-provider support, and better observability. See [MIGRATION_TO_STRANDS.md](MIGRATION_TO_STRANDS.md) for details.

## Features

- **Strands-Powered**: Built on the [Strands Agents SDK](https://strandsagents.com/) for robust agent orchestration
- **Interactive TUI**: Beautiful terminal interface with real-time updates
- **Wikipedia Tools**: Strands tools for searching, retrieving, and citing Wikipedia articles
- **Multiple LLM Backends**: Support for Ollama (local), OpenRouter (cloud), and more via Strands
- **Dual Output Modes**: 
  - **MLA Mode**: Comprehensive responses with properly formatted MLA 9th edition citations
  - **JSON Mode**: Structured data with sources, facts, and references for programmatic use
- **Configurable**: YAML-based configuration with environment variable support
- **Streaming Support**: Real-time streaming responses from LLMs
- **Template System**: Customizable prompts with citation enforcement

## Installation

```bash
# Using pip
pip install -e .

# Or using uv (recommended)
uv venv
uv pip install -e .

# For development
uv pip install -e ".[dev]"
```

## Configuration

1. Copy `.env.example` to `.env` and add your API keys:
```bash
cp .env.example .env
```

2. Edit `config.yaml` to configure your LLM provider:

```yaml
llm:
  provider: "ollama"  # or "openrouter"

  ollama:
    base_url: "http://masterroshi:11434"
    model: "llama3.2"
    temperature: 0.7
    # Optional allowlistâ€”only these models will appear in the UI (default: all).
    allowed_models:
      - "llama3.2"
      - "llama3.1"

  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    api_key_env: "OPENROUTER_API_KEY"
    model: "anthropic/claude-3.5-sonnet"
    temperature: 0.7
    # Optional allowlistâ€”only these OpenRouter models will show up and be selectable.
    allowed_models:
      - "anthropic/claude-3.5-sonnet"
      - "anthropic/claude-3.5-haiku"

wikipedia:
  language: "en"
  max_articles: 3
  max_chars_per_article: 3000

agent:
  stream_response: true
  enforce_citations: true
  output_format: "mla"  # mla | json
```

### Output Formats

The agent supports two output formats:

#### MLA Format (Default)
Returns a comprehensive narrative response with proper MLA 9th edition citations.

```yaml
agent:
  output_format: "mla"
```

Example output:
```
Quantum computing is a revolutionary approach to computation that leverages
quantum mechanical phenomena like superposition and entanglement...

Works Cited
"Quantum Computing." Wikipedia, Wikimedia Foundation, 15 Nov. 2024,
    en.wikipedia.org/wiki/Quantum_computing. Accessed 22 Nov. 2025.
```

#### JSON Format
Returns structured data with sources and facts, ideal for programmatic use.

**How It Works:** JSON mode now uses **Strands Structured Output** directly with the `FactOutput` model and an expanded catalog:
1. LLM reads the retrieved Wikipedia articles and constructs a JSON document that matches `FactOutput`
2. Facts are grouped into `facts`, and the catalog includes explicit `people`, `places`, `events`, and `ideas`, each linked to their sources
3. Relationships between those entities (e.g., founding fathers connected via the Declaration of Independence) are exposed in the `relations` array with optional dates and supporting sources
4. The agent validates the structured output, ensuring every response conforms to the documented schema
5. The final response is a guaranteed, type-safe JSON object ready for programmatic consumption

This approach keeps the LLM focused on signal extraction while Strands handles formatting, validation, and error reporting.

```yaml
agent:
  output_format: "json"
```

Example output:
```json
{
  "query": "What is quantum computing?",
  "sources": [
    {
      "id": "source_1",
      "title": "Quantum computing",
      "url": "https://en.wikipedia.org/wiki/Quantum_computing",
      "last_modified": "2024-11-15",
      "word_count": 5000
    }
  ],
  "facts": [
    {
      "fact": "Quantum computing uses quantum bits (qubits) which can exist in superposition",
      "source_ids": ["source_1"],
      "category": "definition"
    },
    {
      "fact": "Quantum computers can solve certain problems exponentially faster than classical computers",
      "source_ids": ["source_1", "source_2"],
      "category": "application"
    }
  ],
  "summary": "Quantum computing leverages quantum mechanical phenomena to perform computations. It uses qubits that can exist in superposition, enabling exponential speedup for specific problems."
}
```

**Fact Categories:** `definition`, `history`, `application`, `technical`, `other`

See [JSON_MODE_FEATURE.md](JSON_MODE_FEATURE.md) for complete details on the architecture.

## Usage

### Web Service (NEW!)

Launch the web interface with REST API:

```bash
# Using the installed command
wikipedia-agent-web

# Or with custom config
wikipedia-agent-web --config custom-config.yaml --port 8000

# Or using Docker (recommended for production)
docker-compose up -d
```

Then open your browser to: **http://localhost:8000**

The web service provides:
- ğŸŒ **Modern web UI** for interactive queries
- ğŸ”Œ **REST API** with streaming support
- ğŸ“Š **API documentation** at `/docs`
- ğŸ³ **Docker support** for easy deployment
- ğŸ› ï¸ **Provider + model selector** in the web UI (choose Ollama or OpenRouter and pick from the configured allowlist)

See [DOCKER_DEPLOYMENT.md](DOCKER_DEPLOYMENT.md) for complete Docker deployment guide.

### Terminal UI (Default)

Launch the interactive TUI:

```bash
# Using the installed command
wikipedia-agent

# Or with Python
python -m src.tui.app

# With custom config
wikipedia-agent custom-config.yaml
```

**TUI Keyboard Shortcuts:**
- `Enter` - Submit question
- `Ctrl+N` - New question (clear input)
- `Ctrl+L` - Clear response display
- `F1` - Show help
- `Ctrl+C` - Quit

### Command Line Interface

For non-interactive use:

```bash
# Using the CLI command
wikipedia-agent-cli "What is quantum computing?"

# With custom config
wikipedia-agent-cli "Explain photosynthesis" --config custom-config.yaml

# Non-streaming mode
wikipedia-agent-cli "History of Python" --no-stream
```

### Python API

```python
from src.agent import WikipediaAgent
from src.config import Config

# Initialize agent
config = Config("config.yaml")
agent = WikipediaAgent(config)

# Query with streaming
for chunk in agent.query("What is machine learning?", stream=True):
    print(chunk, end="", flush=True)

# Query without streaming
response = agent.query("What is artificial intelligence?", stream=False)
print(response)

# Use JSON mode
from src.config import Config
config = Config("config.yaml")
config._config["agent"]["output_format"] = "json"
json_agent = WikipediaAgent(config)
json_response = json_agent.query("What is machine learning?", stream=False)
print(json_response)  # Returns structured JSON
```

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_wikipedia.py
```

## Project Structure

```
wikipedia-agent/
â”œâ”€â”€ pyproject.toml          # Project dependencies
â”œâ”€â”€ config.yaml             # Configuration file
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ system.yaml         # Prompt templates
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py            # Core agent logic
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”œâ”€â”€ prompts.py          # Prompt template loader
â”‚   â”œâ”€â”€ main.py             # CLI interface
â”‚   â”œâ”€â”€ tui/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py          # Terminal UI application
â”‚   â”œâ”€â”€ wikipedia/
â”‚   â”‚   â”œâ”€â”€ search.py       # Wikipedia search
â”‚   â”‚   â””â”€â”€ citation.py     # MLA citation generator
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ base.py         # LLM provider interface
â”‚       â”œâ”€â”€ ollama.py       # Ollama implementation
â”‚       â””â”€â”€ openrouter.py   # OpenRouter implementation
â””â”€â”€ tests/
    â”œâ”€â”€ test_wikipedia.py   # Wikipedia tests
    â”œâ”€â”€ test_llm.py         # LLM provider tests
    â”œâ”€â”€ test_agent.py       # Agent workflow tests
    â””â”€â”€ test_config.py      # Config tests
```

## TUI Interface

The Terminal UI provides an intuitive interface with:

**Left Panel - Wikipedia Articles:**
- List of found articles with word counts
- Direct links to source articles
- Updates in real-time during search

**Right Panel - Response & Input:**
- Streaming LLM responses with markdown formatting
- Question input field at the bottom
- MLA citations included automatically

**Status Bar:**
- Current LLM provider and model
- Real-time status (Ready, Searching, Generating, Error)

**Features:**
- Real-time streaming responses
- Markdown rendering for better readability
- Keyboard shortcuts for quick navigation
- Help screen accessible via F1

## Example Output

```
Question: What is quantum computing?

[Searching Wikipedia...]
Found 3 articles:
â€¢ Quantum computing
â€¢ Qubit
â€¢ Quantum algorithm

[Generating response...]

Quantum computing is a revolutionary approach to computation that leverages
quantum mechanical phenomena like superposition and entanglement to perform
calculations. Unlike classical computers that use bits representing 0 or 1,
quantum computers use qubits which can exist in multiple states simultaneously...

Works Cited
"Quantum Computing." Wikipedia, Wikimedia Foundation, en.wikipedia.org/wiki/
    Quantum_computing. Accessed 21 Nov. 2025.
"Qubit." Wikipedia, Wikimedia Foundation, en.wikipedia.org/wiki/Qubit.
    Accessed 21 Nov. 2025.
```

## LLM Provider Setup

### Ollama (Local)

1. Install Ollama: https://ollama.ai
2. Pull a model: `ollama pull llama3.2`
3. Start Ollama service
4. Set provider to "ollama" in config.yaml

### OpenRouter (Cloud)

1. Get API key from https://openrouter.ai
2. Add key to `.env` as `OPENROUTER_API_KEY`
3. Set provider to "openrouter" in config.yaml

## License

